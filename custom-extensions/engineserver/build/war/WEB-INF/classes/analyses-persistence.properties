# This file lists all the middle tier related properties, the values in this 
# file are intended for tuning the middle tier by Calypso staff.  These values 
# should not be altered by clients unless instructured to do so by Calypso support 
# or professional services.


# Overview
#######################################################################################
#	In order to better understand the properties and their impact this section describes
#   the standard flow of an analysis run in middle tier:
#
#	The CWS can display reports that are run in the Calculation Server or those saved 
# 	via Schedule Tasks to the Core Calypso DB. The interaction with the middle tier 
#	database can be explained in brief using the following steps
#
#1. The necessary tables and views for a report are created. One table is created 
#	to store the data (maybe more in the case of Sybase if the page size is smaller 
#	than what is required for the report) and another table is created to facilitate 
#	the deleting of old rows (see step no 4 for more details). One view is created 
#	for the purpose of rendering the view for the CWS. Note that a separate set of 
#	tables/views is created each time a new analysis is run
#
#2. The analysis output is translated to the middle tier format and saved. Note
# 	that when the grid is used, the output is saved as it is generated, meaning that 
# 	we do not wait for the entire analysis to complete to start persisting the results.
#
#3. The data, when inserted in the table is not made visible to the user till all rows are saved. 
# 	The reason for doing so is to guanrantee a consistent view for the user. This is done by 
#   waiting for all the rows to be inserted and then the rows are marked as visible in a single transaction.
#
#4. In the case of an incremental update (not applicable when the CWS is used to dispay a 
#	report saved by the schedule task), it is also necessary to delete the old rows that are 
#	no longer relevant. This is done in the same transaction as step no. 3
#
#5. As users request views, they are retrieved from the database. Database operations are 
#	used to minimize the number of rows returned by the query which reduces the memory 
#	and cpu requirements of the presentation server.
#
#6. Finally, when the report is unloaded (there are various ways this can happen), 
#	the tables corresponding to a report are deleted.


# SQL Templates
#######################################################################################
# The following section defines the templates for SQL executed during the analysis run
# (Steps 1, 3, 4 and 6 described above)

# Templates for the table names being used in the CS
# {0} is automatically populated by the CS to a generated unique name 
middletier_store.data_table.name=cs_{0}
middletier_store.delete_table_prefix=cs_del_{0}

# Templates for the table creation, these allow for users to control
# vendor specific features when creating tables including tablespaces, additional
# indexes and parallelization
middletier_store.schema.create.sybase=CREATE TABLE {0} ( {1} )
middletier_store.schema.create.postgres=CREATE UNLOGGED TABLE {0} ( {1} )

# -------------------------------------------------------------------------- 
# Standalone installation 
middletier_store.schema.create.oracle=CREATE TABLE {0} ( {1} ) nologging

# Templates for controlling the structure of the temporary tables that 
# hold the outputrowids of rows that need to be deleted

middletier_store.schema.delete_table.create.sybase=CREATE TABLE {0} ( {1} )
middletier_store.schema.delete_table.create.postgres=CREATE UNLOGGED TABLE {0} ( {1} )
# -------------------------------------------------------------------------- 
# Standalone installation 
middletier_store.schema.delete_table.create.oracle=CREATE GLOBAL TEMPORARY TABLE {0} ( {1} )
# Multi-Tenancy installation
# middletier_store.schema.delete_table.create.oracle=CREATE GLOBAL TEMPORARY TABLE {0} (tenant_id numeric  DEFAULT SYS_CONTEXT(''USERENV'', ''CLIENT_IDENTIFIER'') NOT NULL,  {1} )
# -------------------------------------------------------------------------- 


# Templates for statement for creating views against the many tables created
# under Sybase to get around Sybase table limitations.
middletier_store.view.create.sybase=CREATE VIEW {0} AS SELECT {1} FROM {2} {3}
middletier_store.view.create.postgres=CREATE VIEW {0} AS SELECT {1} FROM {2} {3}
middletier_store.view.create.oracle=CREATE VIEW {0} AS SELECT {1} FROM {2} {3} 

# Templates for the statements that get executed in the end of a run, 
# which will make new rows become available for users to view
middletier_store.statement.update.markRowsVisibility.oracle=UPDATE /*+ PARALLEL ( {0},8 ) */ {0} {1}
middletier_store.statement.update.markRowsVisibility.sybase=UPDATE {0} {1}
middletier_store.statement.update.markRowsVisibility.postgres=UPDATE {0} {1}

# Templates for statement that gets executed in the end of a run, 
# these will be used to remove all the rows from the main table 
# which exist in the delete (temporary table) 
middletier_store.statement.delete.deleteOldRows.oracle=DELETE /*+ PARALLEL ( {0}, 8)*/ FROM {0} WHERE EXISTS ( SELECT /*+ PARALLEL({1},8)*/ * FROM {1} WHERE {0}.{2}={1}.{2} )
middletier_store.statement.delete.deleteOldRows.sybase=DELETE FROM {0} WHERE EXISTS ( SELECT * FROM {1} WHERE {0}.{2}={1}.{2} )
middletier_store.statement.delete.deleteOldRows.postgres=DELETE FROM {0} WHERE EXISTS ( SELECT * FROM {1} WHERE {0}.{2}={1}.{2} )

# Templates for statement for dropping tables and views (Step 6 described above)
middletier_store.schema.drop=DROP TABLE {0} 
middletier_store.view.drop=DROP VIEW {0} 


# Parallelizing of threads and batching
#######################################################################################
# The following are the variables that control the threading and batching in middle tier 
# when saving results into middle tier database
# Step 2 described above

# This attribute controls the number of threads used to save the results of 
# a given analysis in order to improve the performance of writes of large 
# analysis results.  This number controls the threads created for each analysis 
# run inside of this CS.  This implies that if the number is set to 10 and there
# are 2 analysis configured there will be at one point 20 threads attempting
# to write results to the database.
#
# Calypso also makes use of prepared statements and JDBC batching to save round trips 
# to the database.  In doing so multiple rows are sent as one action to the db.
# The persistor threads described make use of JDBC batches of 100 rows
persistor.thread=10

# This property controls the number of rows collected before this batch is passed on to
# the threads waiting to write data to the database.
persistor.batchsize=1000

# This queue size determines the number of batches allowed to be held on to in memory
# waiting to be consumed by the persistor threads which are writing the results.  For example
# if all persistor threads are blocked, and batch size is set to 1000 with this parameter set to
# 20, there can be only 20000 rows (or 20 batches) queues before the analysis is blocked 
# waiting for results to be written
persistor.write_queue_size=20

# Determines whether the CS should save debug messages into database
# this is very expensive and should NOT be turned on in ANY production environment
rodsw.enable_update_logging=false

# The following are default persistors for all analysis to define a persistor 
# for a specific analysis, prefix this key with the analysis name
# These values should not be modified
dal.permanent=com.calypso.tk.risk.sql.DefaultAnalysisOutputPermDAL
dal.temporary=com.calypso.tk.risk.DefaultAnalysisOutputTempDAL

# persistor for the crossassetpl analysis
crossassetpl.dal.temporary=com.calypso.tk.risk.CrossAssetPLAnalysisOutputTempDAL
# persistor for the officialpl analysis
officialpl.dal.temporary=com.calypso.tk.risk.OfficialPLAnalysisOutputTempDAL
# persistor for the rebalacning analysis
rebalancing.dal.temporary=com.calypso.tk.risk.RebalancingAnalysisOutputTempDAL

# Query and executing results for view requests from CWS
#######################################################################################
# The following are the variables that control the query results in presentation server
# Step 5 described above

# Maximum number of rows allowed to be read into memory by the PS for a given view request.  
# Any view request for results larger than this number of rows will result in an error displayed
# to the user indicating that the request should be changed.
query.row_limit=50000


# Additive key is an extra column added to the set of columns used to persist measures.  
# This column holds usually currency used to calculate the measure and is used by the PS to 
# keep users from requesting aggregations across rows which do not make sense 
# (ie NPV for row 1=10 USD, NPV for row 2=20 JPY).
#  
# For analysis which support this functionality, the PS returns empty aggregation results when 
# the additive keys for the rows being aggregated do not match.  This feature cannot be supported 
# with large number of columns in the view under Sybase due to limitations in the table widths, 
# number of supported work tables and other Sybase limitations.
# Not all measures support this feature implying some results are still additive despite them being 
# generated under different additive keys (currencies). 
# ***************************** WARNING *********************************************************
# Disabling this feature can result in end user generating numbers which do not make sense.  Do NOT
# disable without understanding the implications of doing so.
configuration.ENABLE_ADDITIVE_KEY_MT=true



# The following properties are hints that are appended to the select query executed by the presentation server
# to get a better performance. In the case of oracle, this will parallelize the query to take advantage
# of multiple CPUs available for execution. 
#
view.select.hint.oracle=/*+ PARALLEL({0},1) */
view.select.hint.sybase=
view.select.hint.postgres=


# Other parameters
#######################################################################################

# This is the number of events which can be queued during the initialization of the portfolio.  
# If this queue size is exceeded (for portfolios that take a very long time to load), the 
# entire analysis will be canceled.
rodsw.MaxEventsInWorkerQueue=100000

# This parameter controls whether we should be running an analysis locally if the number of 
# jobs created is 1 though the analysis has been configured to use the grid
grid.RunSingleJobLocally=true

